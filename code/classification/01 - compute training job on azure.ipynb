{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Company Name:**\n",
    "- Major Hospital\n",
    "\n",
    "**Problem Type:**\n",
    "\n",
    "- Classification (Multi Class)\n",
    "\n",
    "**Problem:**\n",
    "- The company wants to automate the classification of patients depending on if they have hepatitis or not and if so, what category of hepatitis they have.\n",
    "\n",
    "**Goal:**\n",
    "- These details (features we will use to predict) are as follows:\n",
    "  - X (Patient ID/No.)\n",
    "  - Age (in years)\n",
    "  - Sex (f,m)\n",
    "  - ALB\n",
    "  - ALP\n",
    "  - ALT\n",
    "  - AST\n",
    "  - BIL\n",
    "  - CHE\n",
    "  - CHOL\n",
    "  - CREA\n",
    "  - GGT\n",
    "  - PROT\n",
    "\n",
    "\n",
    "- Which will let us determine the target variable which is:\n",
    "  - Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')\n",
    "  - We have encoded the Category column so, 0, 1, 2, 3, 4 correspond respectively to '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Understand the training code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('data/train.parquet')\n",
    "\n",
    "test = pd.read_parquet('data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data into features X and targets Y.\n",
    "le = LabelEncoder()\n",
    "\n",
    "target_column_name = 'Category'\n",
    "Y_train = train[target_column_name]\n",
    "X_train = train.drop([target_column_name], axis = 1)  \n",
    "Y_test = test[target_column_name]\n",
    "X_test = test.drop([target_column_name], axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "487    0\n",
       "488    0\n",
       "489    0\n",
       "490    0\n",
       "491    0\n",
       "Name: Category, Length: 492, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Accuracy score:  0.8780487804878049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Transform string data to numeric one-hot vectors\n",
    "\n",
    "categorical_selector = selector(dtype_exclude=np.number)\n",
    "categorical_columns = categorical_selector(X_train)\n",
    "categorial_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Standardize numeric data by removing the mean and scaling to unit variance\n",
    "numerical_selector = selector(dtype_include=np.number)\n",
    "numerical_columns = numerical_selector(X_train)\n",
    "numerical_encoder = StandardScaler()\n",
    "\n",
    "# Filling missing values in the training set with the 10% trim_mean of the column\n",
    "for col in numerical_columns:\n",
    "    X_train[col].fillna(trim_mean(X_train[col], 0.1), inplace=True)\n",
    "\n",
    "# Filling missing values in the testing set with the 10% trim_mean of the column\n",
    "for col in numerical_columns:\n",
    "    X_test[col].fillna(trim_mean(X_test[col], 0.1), inplace=True)\n",
    "\n",
    "# Create a preprocessor that will preprocess both numeric and categorical data\n",
    "preprocessor = ColumnTransformer([('categorical-encoder', categorial_encoder, categorical_columns),('standard_scaler', numerical_encoder, numerical_columns)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf  = make_pipeline(preprocessor, RandomForestClassifier()) \n",
    "\n",
    "print('Training model...') \n",
    "\n",
    "model = rf.fit(X_train, Y_train)\n",
    "\n",
    "print('Accuracy score: ', rf.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create a cloud client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Register the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading train.parquet\u001b[32m (< 1 MB): 100%|██████████| 25.2k/25.2k [00:00<00:00, 146kB/s]\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading test.parquet\u001b[32m (< 1 MB): 100%|██████████| 14.5k/14.5k [00:00<00:00, 87.1kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "train_data_name = 'hepatitis_c_train_parquet'\n",
    "test_data_name = 'hepatitis_c_test_parquet'\n",
    "training_data = Data(    name=train_data_name,    \n",
    "                path='data/train.parquet',    \n",
    "                type=AssetTypes.URI_FILE,    \n",
    "                description='RAI hepatitis c train data')\n",
    "\n",
    "tr_data = ml_client.data.create_or_update(training_data)\n",
    "test_data = Data(    name=test_data_name,    \n",
    "                path='data/test.parquet',    \n",
    "                type=AssetTypes.URI_FILE,    \n",
    "                description='RAI hepatitis c test data')\n",
    "                \n",
    "ts_data = ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1684434419020
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'trainingcompute', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/da96cce7-575d-4d7b-a46c-7f24618285e4/resourceGroups/rg-ms-learn/providers/Microsoft.MachineLearningServices/workspaces/azmlwksp/computes/trainingcompute', 'Resource__source_path': None, 'base_path': '/workspaces/Azure-ResponsibleAI-Dashboard-Guide/code/classification', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7ff3fec249d0>, 'resource_id': None, 'location': 'eastus2', 'size': 'Standard_DS12_v2', 'min_instances': 0, 'max_instances': 4, 'idle_time_before_scale_down': 3600.0, 'identity': None, 'ssh_public_access_enabled': True, 'ssh_settings': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x7ff3fec243d0>, 'tier': 'dedicated', 'enable_node_public_ip': True, 'subnet': None})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "compute_name = 'trainingcompute'\n",
    "\n",
    "my_compute = AmlCompute(\n",
    "    name=compute_name,\n",
    "    size='Standard_DS12_v2',\n",
    "    min_instances=0,\n",
    "    max_instances=4,\n",
    "    idle_time_before_scale_down=3600\n",
    ")\n",
    "ml_client.compute.begin_create_or_update(my_compute).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1684434758448
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.0 MBs): 100%|██████████| 2646/2646 [00:00<00:00, 29436.91it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: careful_onion_d6nzrkvw5t\n",
      "Web View: https://ml.azure.com/runs/careful_onion_d6nzrkvw5t?wsid=/subscriptions/da96cce7-575d-4d7b-a46c-7f24618285e4/resourcegroups/rg-ms-learn/workspaces/azmlwksp\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: careful_onion_d6nzrkvw5t\n",
      "Web View: https://ml.azure.com/runs/careful_onion_d6nzrkvw5t?wsid=/subscriptions/da96cce7-575d-4d7b-a46c-7f24618285e4/resourcegroups/rg-ms-learn/workspaces/azmlwksp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "\n",
    "target_column_name = 'Category'\n",
    "\n",
    "# Create the job\n",
    "job = command(\n",
    "    description='Trains hepatitis c model',\n",
    "    experiment_name='hepatitis_c_test',\n",
    "    compute=compute_name,\n",
    "    inputs=dict(training_data=Input(type='uri_file', path=f'{train_data_name}@latest'), \n",
    "                target_column_name=target_column_name),\n",
    "    outputs=dict(model_output=Output(type=AssetTypes.MLFLOW_MODEL)),\n",
    "    code='src/',\n",
    "    environment='azureml://registries/azureml/environments/responsibleai-ubuntu20.04-py38-cpu/versions/37',\n",
    "    command='python train.py ' + \n",
    "            '--training_data ${{inputs.training_data}} ' +\n",
    "            '--target_column_name ${{inputs.target_column_name}} ' +\n",
    "            '--model_output ${{outputs.model_output}}'\n",
    ")\n",
    "job = ml_client.jobs.create_or_update(job)\n",
    "ml_client.jobs.stream(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1684434758713
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "model_name = 'hepatitis_c_model'\n",
    "\n",
    "# Register the model.\n",
    "model_path = f'azureml://jobs/{job.name}/outputs/model_output'\n",
    "model = Model(name=model_name,\n",
    "                path=model_path,\n",
    "                type=AssetTypes.MLFLOW_MODEL)\n",
    "registered_model = ml_client.models.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
